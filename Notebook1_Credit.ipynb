{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook1_Credit",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:rds_env]",
      "language": "python",
      "name": "conda-env-rds_env-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu8QNsWRb_xp"
      },
      "source": [
        "# Detecting and Mitigating Age Bias on Credit Decisions \n",
        "\n",
        "By: Ashwin Nalwade.\n",
        "\n",
        "Focus - Basic functionality of AI Fairness 360 for bias mitigation in a dataset.\n",
        "\n",
        "### Biases and Machine Learning\n",
        "\n",
        "A machine learning model predicts an outcome for a particular instance. For example, given an instance of a loan application, we may use a model to predict whether the applicant will repay the loan. The model makes predictions based on a training dataset, where many other instances (other loan applications) and observed outcomes (whether a loan was repaid) are provided. A machine learning algorithm will attempt to find patterns, or generalizations, in the training dataset to use when a prediction for a new instance is needed. For example, the model may discover a pattern whereby a person with a salary over \\$40,000 and  outstanding debt of less than \\$5 is very likely to repay a loan. In many domains this technique, called supervised machine learning, has worked very well.\n",
        "\n",
        "However, sometimes the patterns that are found may not be desirable or may even be illegal. For example, a loan repayment model may determine that age plays a significant role in the prediction of repayment because the training dataset happened to have better repayment for one age group compared to another. This raises two problems: 1) the training dataset may not be representative of the true population of loan applications for all age groups, and 2) even if it is representative, it is illegal (with limited exceptions) to base loan decisions on an applicant's age, regardless of whether this is a accurate basis for prediction based on historical data.\n",
        "\n",
        "AI Fairness 360 is a toolkit designed to help address this problem with _fairness metrics_ and _bias mitigators_.  Fairness metrics can be used to check for bias in machine learning workflows.  Bias mitigators can be used to overcome bias in the workflow to produce a more fair outcome. \n",
        "\n",
        "The loan scenario describes an intuitive example of illegal bias. However, not all undesirable bias in machine learning is illegal; it may also exist in more subtle ways.  For example, a loan company may want a diverse portfolio of customers across all income levels, and thus, will deem it undesirable if they are making more loans to high income levels over low income levels.  Although this is not illegal or unethical, it is undesirable for the company's strategy.\n",
        "\n",
        "As these two examples illustrate, a bias detection and/or mitigation toolkit needs to be tailored to the particular bias of interest.  More specifically, we need to define the attribute(s), called _protected attributes_, of interest.\n",
        "\n",
        "### The Machine Learning Workflow\n",
        "\n",
        "To understand how bias can enter a machine learning model, we first review the basics of how a model is created in a supervised machine learning process.  \n",
        "\n",
        "![image](https://ibmcode-staging.us-east.containers.mybluemix.net/site-content/uploads/2018/09/aif360-1.png)\n",
        "\n",
        "First, the process starts with a _training dataset_, which contains a sequence of instances, where each instance has two components: the features and the outcome for these features.  Next, a machine learning algorithm is trained on this training dataset to produce a machine learning model.  This generated model can be used to make a prediction when given a new instance.  A second dataset with features and outcomes, called a _test dataset_, is used to assess the accuracy of the model.\n",
        "Typically, this test dataset has the same format as the training dataset (a set of instances of features and outcome pairs) and often these two datasets derive from the same initial dataset. For example, a random partitioning algorithm may be used to split the initial dataset into training and test data subsets.\n",
        "\n",
        "Bias can enter the system in any of the three steps above. The training data set may be biased if a particular outcome is overrepresented for some types of instances. The algorithm may be biased if it assigns importance to particular features in the input that we believe should not be used or if the model produces predictions that are systematically less favorable to instances with particular features. The test data set may be biased if it has observed outcomes that are unrepresentative of the broader population of instances. These examples are not exhaustive; bias can enter the machine learning process in several other ways.\n",
        "\n",
        "These three points in the machine learning process represent stages for testing and mitigating bias. In the AI Fairness 360 codebase, we call these stages _pre-processing_, _in-processing_, and _post-processing_. \n",
        "\n",
        "### AI Fairness 360\n",
        "\n",
        "We are now ready to utilize AI Fairness 360 (`aif360`) to detect and mitigate bias. We will use the German credit dataset, splitting the data into a training and test dataset.  We will look for bias in the creation of a machine learning model that predicts whether an applicant should be given credit based on various features from a typical credit application. The protected attribute will be \"Age\", with \"1\" (older than or equal to 25) and \"0\" (younger than 25) being the values for the _privileged_ and _unprivileged_ groups, respectively.\n",
        "\n",
        "In this notebook, we will:\n",
        "\n",
        "1. Install and import packages and modules\n",
        "2. Set bias detection options, load dataset, and split between train and test\n",
        "3. Compute fairness metric on original training dataset\n",
        "5. Mitigate bias using an in-processing algorithm (adversarial debiasing) and compute the fairness metrics under this model\n",
        "\n",
        "At the end of the notebook, there are optional exercises to mitigate bias using a pre-processing algorithm and another algorithm of your choosing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSvZzh_-ntSU"
      },
      "source": [
        "\n",
        "## 1 Import Statements\n",
        "\n",
        "First, we install the necessary packages. Then we import several components from the `aif360` package. We also import the GermanDataset, metrics to check for bias, and classes related to the algorithm we will use to mitigate bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_4p0U7o1lnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee099e4-64b7-4d10-a387-a946b0179c69"
      },
      "source": [
        "%pip install numpy matplotlib seaborn\n",
        "!pip install numba==0.48\n",
        "!pip install aif360==0.2.2\n",
        "!python -m pip install BlackBoxAuditing\n",
        "!pip install tensorflow==1.12.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.11.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Collecting numba==0.48\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/7f/dbe85f5f419dca88509d829df90dfa5aefa39c39f6b7020dfc206a386279/numba-0.48.0-1-cp36-cp36m-manylinux2014_x86_64.whl (3.5MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5MB 5.1MB/s \n",
            "\u001b[?25hCollecting llvmlite<0.32.0,>=0.31.0dev0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/bb/60d4033d56c9da36490af19caa6c794b72b8aef6f792fdfa8cb95d11e419/llvmlite-0.31.0-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from numba==0.48) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba==0.48) (53.0.0)\n",
            "\u001b[31mERROR: umap-learn 0.5.0 has requirement numba>=0.49, but you'll have numba 0.48.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pynndescent 0.5.1 has requirement numba>=0.51.2, but you'll have numba 0.48.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: llvmlite, numba\n",
            "  Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed llvmlite-0.31.0 numba-0.48.0\n",
            "Collecting aif360==0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/54/09e0674fc1370072385d64e0282eff0857e3d78c3abd7d6471200cf7a00d/aif360-0.2.2-py2.py3-none-any.whl (56.4MB)\n",
            "\u001b[K     |████████████████████████████████| 56.4MB 65kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.3 in /usr/local/lib/python3.6/dist-packages (from aif360==0.2.2) (1.1.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from aif360==0.2.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from aif360==0.2.2) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from aif360==0.2.2) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.3->aif360==0.2.2) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.3->aif360==0.2.2) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->aif360==0.2.2) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.3->aif360==0.2.2) (1.15.0)\n",
            "Installing collected packages: aif360\n",
            "Successfully installed aif360-0.2.2\n",
            "Collecting BlackBoxAuditing\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/2e/e2e7166bc78eb599b602ca79ace1ceba2ef83b69a0b708c9a7eb729347bf/BlackBoxAuditing-0.1.54.tar.gz (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from BlackBoxAuditing) (2.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from BlackBoxAuditing) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from BlackBoxAuditing) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from BlackBoxAuditing) (1.19.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->BlackBoxAuditing) (4.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->BlackBoxAuditing) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->BlackBoxAuditing) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->BlackBoxAuditing) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->BlackBoxAuditing) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->BlackBoxAuditing) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->BlackBoxAuditing) (1.15.0)\n",
            "Building wheels for collected packages: BlackBoxAuditing\n",
            "  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394769 sha256=c909b03ebc89d28b0aec7959e2e4b9762aeab9a8c9ef1f826c22d669dbd656a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/82/7b/ac2a79b8caf97e15ed415162a7f272cbba1e2e2c851fa76ae3\n",
            "Successfully built BlackBoxAuditing\n",
            "Installing collected packages: BlackBoxAuditing\n",
            "Successfully installed BlackBoxAuditing-0.1.54\n",
            "Collecting tensorflow==1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 48kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.32.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.3.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.36.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.19.5)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.13.0,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0) (53.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.7.4.3)\n",
            "Installing collected packages: keras-applications, tensorboard, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.12.2 tensorflow-1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJxDwiuVb_xt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344a6686-1989-48bb-9774-991fc8a5aef5"
      },
      "source": [
        "# import all necessary packages\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "from aif360.datasets import GermanDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric, DatasetMetric\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
        "from aif360.explainers import MetricTextExplainer, MetricJSONExplainer\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import json\n",
        "from collections import OrderedDict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQj5VqOSb_xt"
      },
      "source": [
        "## 2 Load Data, Specify Protected Attribute, and Split Data\n",
        "\n",
        "Next we'll load the German Credit Risk data and set the protected attribute to be age. We then split the original dataset into training and test data subsets. Although we'll use the training dataset only in this tutorial, a normal workflow would also use a test dataset for assessing the efficacy (accuracy, fairness, etc.) during the development of a machine learning model. Finally, we create two variables to represent the privileged and unprivileged values for the age attribute.\n",
        "\n",
        "The German Credit Risk data contains 1000 entries with 20 categorical and integer attributes prepared. In this dataset, each entry represents a person applying for a loan. Each person is classified as a \"good\" or \"bad\" credit risk. The original dataset can be found at https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29\n",
        "\n",
        "Recall that a _protected attribute_ is the attribute of interest, i.e. the attribute for which you want to test bias. The _privileged class_ is a subset of protected attribute values which we define as privileged from a fairness perspective. In the German dataset, older applicants (age >= 25) are the privileged class and younger applicants (age < 25) are the unprivileged class. We therefore have binary membership in a protected group (age) and a binary classification problem (good or bad credit risk).\n",
        "\n",
        "Let's prepare the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYB3PkStb_xv"
      },
      "source": [
        "# note that we drop sex, which may also be a protected attribute\n",
        "dataset_orig = GermanDataset(protected_attribute_names=['age'],\n",
        "                             privileged_classes=[lambda x: x >= 25],\n",
        "                             features_to_drop=['personal_status', 'sex'])\n",
        "\n",
        "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
        "\n",
        "privileged_groups = [{'age': 1}]\n",
        "unprivileged_groups = [{'age': 0}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsFiFKReb_xw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eaef36d-dbb1-4576-c9c3-49fc8f60e180"
      },
      "source": [
        "print(\"Original one hot encoded german dataset shape: \",dataset_orig.features.shape)\n",
        "print(\"Train dataset shape: \", dataset_orig_train.features.shape)\n",
        "print(\"Test dataset shape: \", dataset_orig_test.features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original one hot encoded german dataset shape:  (1000, 57)\n",
            "Train dataset shape:  (700, 57)\n",
            "Test dataset shape:  (300, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTTLfl2tb_xw"
      },
      "source": [
        "The object ```dataset_orig``` is an aif360 dataset, which has some useful methods and attributes that you can explore. More documentation is available at https://aif360.readthedocs.io/en/latest/modules/datasets.html.\n",
        "\n",
        "For now, we'll just transform the data into a pandas dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3Aonmt3b_xw"
      },
      "source": [
        "df, dict_df = dataset_orig.convert_to_dataframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jax9cvjub_xx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "9d8ac12a-737d-4bef-a920-2aab9e97d3f5"
      },
      "source": [
        "print(\"Shape: \", df.shape)\n",
        "print(df.columns)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape:  (1000, 58)\n",
            "Index(['month', 'credit_amount', 'investment_as_income_percentage',\n",
            "       'residence_since', 'age', 'number_of_credits', 'people_liable_for',\n",
            "       'status=A11', 'status=A12', 'status=A13', 'status=A14',\n",
            "       'credit_history=A30', 'credit_history=A31', 'credit_history=A32',\n",
            "       'credit_history=A33', 'credit_history=A34', 'purpose=A40',\n",
            "       'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43',\n",
            "       'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48',\n",
            "       'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63',\n",
            "       'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72',\n",
            "       'employment=A73', 'employment=A74', 'employment=A75',\n",
            "       'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103',\n",
            "       'property=A121', 'property=A122', 'property=A123', 'property=A124',\n",
            "       'installment_plans=A141', 'installment_plans=A142',\n",
            "       'installment_plans=A143', 'housing=A151', 'housing=A152',\n",
            "       'housing=A153', 'skill_level=A171', 'skill_level=A172',\n",
            "       'skill_level=A173', 'skill_level=A174', 'telephone=A191',\n",
            "       'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202',\n",
            "       'credit'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>investment_as_income_percentage</th>\n",
              "      <th>residence_since</th>\n",
              "      <th>age</th>\n",
              "      <th>number_of_credits</th>\n",
              "      <th>people_liable_for</th>\n",
              "      <th>status=A11</th>\n",
              "      <th>status=A12</th>\n",
              "      <th>status=A13</th>\n",
              "      <th>status=A14</th>\n",
              "      <th>credit_history=A30</th>\n",
              "      <th>credit_history=A31</th>\n",
              "      <th>credit_history=A32</th>\n",
              "      <th>credit_history=A33</th>\n",
              "      <th>credit_history=A34</th>\n",
              "      <th>purpose=A40</th>\n",
              "      <th>purpose=A41</th>\n",
              "      <th>purpose=A410</th>\n",
              "      <th>purpose=A42</th>\n",
              "      <th>purpose=A43</th>\n",
              "      <th>purpose=A44</th>\n",
              "      <th>purpose=A45</th>\n",
              "      <th>purpose=A46</th>\n",
              "      <th>purpose=A48</th>\n",
              "      <th>purpose=A49</th>\n",
              "      <th>savings=A61</th>\n",
              "      <th>savings=A62</th>\n",
              "      <th>savings=A63</th>\n",
              "      <th>savings=A64</th>\n",
              "      <th>savings=A65</th>\n",
              "      <th>employment=A71</th>\n",
              "      <th>employment=A72</th>\n",
              "      <th>employment=A73</th>\n",
              "      <th>employment=A74</th>\n",
              "      <th>employment=A75</th>\n",
              "      <th>other_debtors=A101</th>\n",
              "      <th>other_debtors=A102</th>\n",
              "      <th>other_debtors=A103</th>\n",
              "      <th>property=A121</th>\n",
              "      <th>property=A122</th>\n",
              "      <th>property=A123</th>\n",
              "      <th>property=A124</th>\n",
              "      <th>installment_plans=A141</th>\n",
              "      <th>installment_plans=A142</th>\n",
              "      <th>installment_plans=A143</th>\n",
              "      <th>housing=A151</th>\n",
              "      <th>housing=A152</th>\n",
              "      <th>housing=A153</th>\n",
              "      <th>skill_level=A171</th>\n",
              "      <th>skill_level=A172</th>\n",
              "      <th>skill_level=A173</th>\n",
              "      <th>skill_level=A174</th>\n",
              "      <th>telephone=A191</th>\n",
              "      <th>telephone=A192</th>\n",
              "      <th>foreign_worker=A201</th>\n",
              "      <th>foreign_worker=A202</th>\n",
              "      <th>credit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1169.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48.0</td>\n",
              "      <td>5951.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12.0</td>\n",
              "      <td>2096.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42.0</td>\n",
              "      <td>7882.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24.0</td>\n",
              "      <td>4870.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   month  credit_amount  ...  foreign_worker=A202  credit\n",
              "0    6.0         1169.0  ...                  0.0     1.0\n",
              "1   48.0         5951.0  ...                  0.0     2.0\n",
              "2   12.0         2096.0  ...                  0.0     1.0\n",
              "3   42.0         7882.0  ...                  0.0     1.0\n",
              "4   24.0         4870.0  ...                  0.0     2.0\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEeX43jZb_xy"
      },
      "source": [
        "Let's take a look at our primary variables of interest: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdG0eNdyb_xz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "e8f06aee-9e61-4ba4-c419-0a591eb82762"
      },
      "source": [
        "print(\"Key: \", dataset_orig.metadata['protected_attribute_maps'][1])\n",
        "df['age'].value_counts().plot(kind='bar')\n",
        "plt.xlabel(\"Age (0 = under 25, 1 = over 25)\")\n",
        "plt.ylabel(\"Frequency\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Key:  {1.0: 'Old', 0.0: 'Young'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Frequency')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50wiFbnvb_xz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "a9b12ca8-c4c0-49f5-f4da-bae5fdd3dda5"
      },
      "source": [
        "print(\"Key: \", dataset_orig.metadata['label_maps'])\n",
        "df['credit'].value_counts().plot(kind='bar')\n",
        "plt.xlabel(\"Credit (1 = Good Credit, 2 = Bad Credit)\")\n",
        "plt.ylabel(\"Frequency\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Key:  [{1.0: 'Good Credit', 2.0: 'Bad Credit'}]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Frequency')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm8RQJL8b_xz"
      },
      "source": [
        "Take a minute to explore the relationship between these two variables. Do credit scores vary with age? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGiFK1L3b_xz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "f5eb748b-2adb-4310-a1fb-a810ca734781"
      },
      "source": [
        "# write your code here\n",
        "import pandas as pd\n",
        "pd.crosstab(df['credit'], df['age'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>age</th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>credit</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>88</td>\n",
              "      <td>612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>61</td>\n",
              "      <td>239</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "age     0.0  1.0\n",
              "credit          \n",
              "1.0      88  612\n",
              "2.0      61  239"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXZn5F8EPThh"
      },
      "source": [
        "88/147 (or 59.86% ) of people under 25 are associated with good credit, whereas 612/851 (or 71.91%) of people over 25 are associated with good credit (a larger number and a larger percentage). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kITY3AtDb_xz"
      },
      "source": [
        "## 3 Compute Fairness Metrics on Original Training Data\n",
        "Now that we've identified the protected attribute \"age\" and defined privileged and unprivileged values, we can use aif360 to detect bias in the dataset.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZLVzqlmwOXI"
      },
      "source": [
        "### Mean Outcomes\n",
        "\n",
        "Compare the percentage of favorable results for the privileged and unprivileged groups, subtracting the former percentage from the latter. This is equivalent to the mean difference in outcomes by group. A value of 0 indicates parity. A value less than 0 indicates less favorable outcomes for the unprivileged groups.  \n",
        "\n",
        "This is implemented in the method called ```mean_difference``` on the BinaryLabelDatasetMetric class.  The code below performs this check and displays the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVQWXC8Ub_x0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e3eefe-821d-4a68-ab24-940e9d66c72c"
      },
      "source": [
        "metric_orig_train = BinaryLabelDatasetMetric(\n",
        "     dataset_orig_train, \n",
        "     unprivileged_groups=unprivileged_groups,\n",
        "     privileged_groups=privileged_groups\n",
        "  )\n",
        "print(\"Original training dataset\")\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original training dataset\n",
            "Difference in mean outcomes between unprivileged and privileged groups = -0.169905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZufOXh9b_x0"
      },
      "source": [
        "### Disparate Impact\n",
        "We can calculate the ratio of predicted favorable outcomes for the unprivileged group compared to the privileged group. A value of 1 would indicate no disparate impact. A value less than 1 implies favorable outcomes for the privileged group and a value greater than 1 implies a favorable outcomes for the unprivileged group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iw7g6Hjb_x0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d38e62-5961-4fd8-abf5-388cc4b39395"
      },
      "source": [
        "print(\"Original training dataset\")\n",
        "print(\"Disparate Impact = %f\" % metric_orig_train.disparate_impact())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original training dataset\n",
            "Disparate Impact = 0.766430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcTiGnSob_x1"
      },
      "source": [
        "### Built-In Explainers\n",
        "\n",
        "```aif360``` has some useful explainers for the fairness metrics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERMXmj2pb_x1"
      },
      "source": [
        "json_expl = MetricJSONExplainer(metric_orig_train)\n",
        "def format_json(json_str):\n",
        "    return json.dumps(json.loads(json_str, object_pairs_hook=OrderedDict),\n",
        "                      indent=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWuosH5pxVHe"
      },
      "source": [
        "Let's print the mean difference explainer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cc0pIUPxdFl",
        "outputId": "a5718c55-c464-4aa8-a601-2cbd7299ef3b"
      },
      "source": [
        "print(format_json(json_expl.mean_difference()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"metric\": \"Mean Difference\",\n",
            "  \"message\": \"Mean difference (mean label value on privileged instances - mean label value on unprivileged instances): -0.1699054740619017\",\n",
            "  \"numPositivesUnprivileged\": 63.0,\n",
            "  \"numInstancesUnprivileged\": 113.0,\n",
            "  \"numPositivesPrivileged\": 427.0,\n",
            "  \"numInstancesPrivileged\": 587.0,\n",
            "  \"description\": \"Computed as the difference of the rate of favorable outcomes received by the unprivileged group to the privileged group.\",\n",
            "  \"ideal\": \"The ideal value of this metric is 0.0\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl-r2vpjxPFo"
      },
      "source": [
        "We can also print the disparate impact explainer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-FoLzMTxSGS",
        "outputId": "8485325d-1bca-4425-8352-f5f0a9c33d9b"
      },
      "source": [
        "print(format_json(json_expl.disparate_impact()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"metric\": \"Disparate Impact\",\n",
            "  \"message\": \"Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.7664297113013201\",\n",
            "  \"numPositivePredictionsUnprivileged\": 63.0,\n",
            "  \"numUnprivileged\": 113.0,\n",
            "  \"numPositivePredictionsPrivileged\": 427.0,\n",
            "  \"numPrivileged\": 587.0,\n",
            "  \"description\": \"Computed as the ratio of rate of favorable outcome for the unprivileged group to that of the privileged group.\",\n",
            "  \"ideal\": \"The ideal value of this metric is 1.0 A value < 1 implies higher benefit for the privileged group and a value >1 implies a higher benefit for the unprivileged group.\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcDleSrDJr_B"
      },
      "source": [
        "Interpret the difference in means and disparate impact in the German Credit data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HV2t23yJ19P"
      },
      "source": [
        "**Analysis**\n",
        "\n",
        "Here, the difference in means has the value ~ -0.17, whereas the disparate impact has the value ~0.76. \n",
        "\n",
        "Since the value for disparate impact is lesser than 1, this implies that a higher degree of benefit exists for the privileged group.\n",
        "\n",
        "Since the value for the difference in means is negative, this (value less than 0) indicates less favorable outcomes for the unprivileged group."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riLalr-WwDsG"
      },
      "source": [
        "## 4 Bias Mitigation via In-Processing\n",
        "\n",
        "In-processing methods focus on the model training stage, as compared to pre-processing which focuses on transforming the data prior to model training. Broadly speaking, contemporary in-processing methods are stronger than pre-processing methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUZKKFAo1R1v"
      },
      "source": [
        "### Adversarial Debiasing\n",
        "\n",
        "In this part of the notebook, we'll use an in-processing algorithm called adversarial debiasing to mitigate the bias in credit prediction with respect to age that we observed in the previous section. From the aif360 documentation (https://aif360.readthedocs.io/en/v0.2.3/modules/inprocessing.html):\n",
        "\n",
        "> Adversarial debiasing is an in-processing technique that learns a classifier to maximize prediction accuracy and simultaneously reduce an adversary’s ability to determine the protected attribute from the predictions. This approach leads to a fair classifier as the predictions cannot carry any group discrimination information that the adversary can exploit.\n",
        "\n",
        "For intuition, you can think of adversarial debiasing as a model with two supervised learning tasks. The first task is to predict an outcome using the training data input. The second task, i.e. the adversary, is to predict a protected feature using these predictions and non-protected features in the training data input. The aim is to maximize the model's ability to carry out the first task (i.e. predict outcomes) while minimizing it's ability to carry out the second task (i.e. predict protected features).\n",
        "\n",
        "We implement adversarial debiasing below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_rWLmHvwBFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "277eb54d-fda4-4b98-d356-04fa1e2b8504"
      },
      "source": [
        "# reset tensorflow graph\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# start tensorflow session\n",
        "sess = tf.Session()\n",
        "\n",
        "# create AdversarialDebiasing model\n",
        "debiased_model = AdversarialDebiasing(\n",
        "    privileged_groups = privileged_groups,\n",
        "    unprivileged_groups = unprivileged_groups,\n",
        "    scope_name = 'debiased_classifier',\n",
        "    debias = True,\n",
        "    sess = sess)\n",
        "\n",
        "# fit the model to training data\n",
        "debiased_model.fit(dataset_orig_train)\n",
        "\n",
        "# make predictions on training and test data\n",
        "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
        "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)\n",
        "\n",
        "# metrics\n",
        "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(\n",
        "    dataset_debiasing_test, \n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        "  )\n",
        "\n",
        "# Close session\n",
        "sess.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0; iter: 0; batch classifier loss: 61.926720; batch adversarial loss: 0.821243\n",
            "epoch 1; iter: 0; batch classifier loss: 39.325760; batch adversarial loss: 0.804206\n",
            "epoch 2; iter: 0; batch classifier loss: 45.632515; batch adversarial loss: 0.778856\n",
            "epoch 3; iter: 0; batch classifier loss: 38.725277; batch adversarial loss: 0.787586\n",
            "epoch 4; iter: 0; batch classifier loss: 31.255611; batch adversarial loss: 0.795027\n",
            "epoch 5; iter: 0; batch classifier loss: 34.416752; batch adversarial loss: 0.765435\n",
            "epoch 6; iter: 0; batch classifier loss: 39.155655; batch adversarial loss: 0.774642\n",
            "epoch 7; iter: 0; batch classifier loss: 39.421291; batch adversarial loss: 0.760773\n",
            "epoch 8; iter: 0; batch classifier loss: 32.630684; batch adversarial loss: 0.742074\n",
            "epoch 9; iter: 0; batch classifier loss: 28.861229; batch adversarial loss: 0.766949\n",
            "epoch 10; iter: 0; batch classifier loss: 38.103493; batch adversarial loss: 0.761876\n",
            "epoch 11; iter: 0; batch classifier loss: 30.272657; batch adversarial loss: 0.756441\n",
            "epoch 12; iter: 0; batch classifier loss: 33.637627; batch adversarial loss: 0.740621\n",
            "epoch 13; iter: 0; batch classifier loss: 34.134609; batch adversarial loss: 0.714202\n",
            "epoch 14; iter: 0; batch classifier loss: 26.677723; batch adversarial loss: 0.731438\n",
            "epoch 15; iter: 0; batch classifier loss: 29.308018; batch adversarial loss: 0.732203\n",
            "epoch 16; iter: 0; batch classifier loss: 29.004717; batch adversarial loss: 0.739730\n",
            "epoch 17; iter: 0; batch classifier loss: 17.991749; batch adversarial loss: 0.714343\n",
            "epoch 18; iter: 0; batch classifier loss: 21.079739; batch adversarial loss: 0.715946\n",
            "epoch 19; iter: 0; batch classifier loss: 13.955579; batch adversarial loss: 0.697008\n",
            "epoch 20; iter: 0; batch classifier loss: 22.766224; batch adversarial loss: 0.718743\n",
            "epoch 21; iter: 0; batch classifier loss: 15.654041; batch adversarial loss: 0.712243\n",
            "epoch 22; iter: 0; batch classifier loss: 27.224869; batch adversarial loss: 0.708927\n",
            "epoch 23; iter: 0; batch classifier loss: 20.828054; batch adversarial loss: 0.688942\n",
            "epoch 24; iter: 0; batch classifier loss: 11.846164; batch adversarial loss: 0.695971\n",
            "epoch 25; iter: 0; batch classifier loss: 20.422680; batch adversarial loss: 0.698155\n",
            "epoch 26; iter: 0; batch classifier loss: 19.891600; batch adversarial loss: 0.687485\n",
            "epoch 27; iter: 0; batch classifier loss: 19.904530; batch adversarial loss: 0.688068\n",
            "epoch 28; iter: 0; batch classifier loss: 20.739048; batch adversarial loss: 0.687412\n",
            "epoch 29; iter: 0; batch classifier loss: 14.398017; batch adversarial loss: 0.683413\n",
            "epoch 30; iter: 0; batch classifier loss: 13.636339; batch adversarial loss: 0.669513\n",
            "epoch 31; iter: 0; batch classifier loss: 11.534743; batch adversarial loss: 0.660447\n",
            "epoch 32; iter: 0; batch classifier loss: 14.367884; batch adversarial loss: 0.673432\n",
            "epoch 33; iter: 0; batch classifier loss: 11.019936; batch adversarial loss: 0.675476\n",
            "epoch 34; iter: 0; batch classifier loss: 7.575730; batch adversarial loss: 0.659901\n",
            "epoch 35; iter: 0; batch classifier loss: 12.435663; batch adversarial loss: 0.655179\n",
            "epoch 36; iter: 0; batch classifier loss: 12.021589; batch adversarial loss: 0.652308\n",
            "epoch 37; iter: 0; batch classifier loss: 5.371550; batch adversarial loss: 0.658663\n",
            "epoch 38; iter: 0; batch classifier loss: 7.372392; batch adversarial loss: 0.654606\n",
            "epoch 39; iter: 0; batch classifier loss: 6.641665; batch adversarial loss: 0.642533\n",
            "epoch 40; iter: 0; batch classifier loss: 8.550089; batch adversarial loss: 0.642624\n",
            "epoch 41; iter: 0; batch classifier loss: 5.439563; batch adversarial loss: 0.639758\n",
            "epoch 42; iter: 0; batch classifier loss: 5.354741; batch adversarial loss: 0.633697\n",
            "epoch 43; iter: 0; batch classifier loss: 7.515809; batch adversarial loss: 0.649203\n",
            "epoch 44; iter: 0; batch classifier loss: 5.025196; batch adversarial loss: 0.625420\n",
            "epoch 45; iter: 0; batch classifier loss: 6.311419; batch adversarial loss: 0.634512\n",
            "epoch 46; iter: 0; batch classifier loss: 3.516751; batch adversarial loss: 0.616492\n",
            "epoch 47; iter: 0; batch classifier loss: 4.657413; batch adversarial loss: 0.615340\n",
            "epoch 48; iter: 0; batch classifier loss: 3.855076; batch adversarial loss: 0.620180\n",
            "epoch 49; iter: 0; batch classifier loss: 5.510464; batch adversarial loss: 0.610560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWJUD_1-1XOe"
      },
      "source": [
        "### Fairness Metrics under Adversarial Debiasing\n",
        "\n",
        "The adversarial debiasing algorithm has built-in methods for the difference in mean outcomes (called ```.mean_difference()```) and disparate impact (called ```.disparate_impact()```). Print these below: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro-8nuS62NZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3715a2c1-6cac-46c4-f72d-83fdc4b79ca1"
      },
      "source": [
        "print(metric_dataset_debiasing_test.mean_difference())\n",
        "print(metric_dataset_debiasing_test.disparate_impact())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3MyIpCk7hnp"
      },
      "source": [
        "**Analysis**\n",
        "\n",
        "After adversarial debiasing, we now have a mean difference of 0.0 and a disparate impact of 1.0, which are both ideal values to have. In comparison, when we consider the metrics calculated on the original data - the difference in means had the value ~ -0.17, whereas the disparate impact had the value ~0.76. Thus, we can say that adversarial debiasing, an in-processing algorithm, has been able to mitigate the bias in credit prediction with respect to age (that we observed for the original data). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Urlnzy3b_x5"
      },
      "source": [
        "## Summary\n",
        "The purpose of this notebook is to introduce some of the functionality of AI Fairness 360 for detecting and mitigating bias. We used an in-processing algorithm called adversarial debiasing. Below, you can run through an implementation of a pre-processing algorithm called reweighing.\n",
        "\n",
        "There are many metrics one can use to detect the presence of bias. Likewise, there are many different bias mitigation algorithms one can employ. AI Fairness 360 provides some of them most common metrics and algorithms. In Lab 4, we will use a different package to further explore bias detection and mitigation.\n",
        "\n",
        "Fairness metrics and mitigation algorithms can be calculated and used in the pre-processing, in-processing, and post-processing stages of the machine learning pipeline. The metrics and algorithms you use will depend, in part, on the particular fairness concerns associated with a machine learning task. We recommend incorporating bias detection in an automated continuous integration pipeline to ensure bias awareness as a project evolves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQIwiWcKb_x3"
      },
      "source": [
        "## Bias Mitigation via Pre-Processing\n",
        "\n",
        "_Pre-processing_ mitigation happens before the creation of the model.  \n",
        "\n",
        "AI Fairness 360 implements several pre-processing mitigation algorithms.  We will use the **reweighing algorithm**, which is implemented in the `Reweighing` class in the `aif360.algorithms.preprocessing` package. This algorithm will transform the dataset to enhance equity in positive outcomes on the protected attribute for the privileged and unprivileged groups.\n",
        "\n",
        "You can find documentation for reweighting here:\n",
        "https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.preprocessing.Reweighing.html \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOIBqkDSb_x3"
      },
      "source": [
        "### Reweighing\n",
        "\n",
        "Reweighing is a data preprocessing technique that generates weights for the training instances to ensure fairness before classification. The idea is to apply appropriate weights to different tuples in the training data to reduce discrimination with respect to the protected attributes. Instead of reweighing, one could also apply techniques such as suppression, i.e. removing sensitive attributes. However, the reweighing technique is generally more effective.\n",
        "\n",
        "Call the fit and transform methods to perform the transformation, producing a newly transformed training dataset (```dataset_transf_train```):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqBmaYXab_x3"
      },
      "source": [
        "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
        "                privileged_groups=privileged_groups)\n",
        "dataset_transf_train = RW.fit_transform(dataset_orig_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdkCX8Fd0zgN"
      },
      "source": [
        "We can print the weights. Each observation in the data should have a weight. For brevity, we'll look at the weights for the first 10 rows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5ISRhOwb_x3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c70a483-3a9f-43ae-9d5d-ae77faf01842"
      },
      "source": [
        "len(dataset_transf_train.instance_weights)\n",
        "dataset_transf_train.instance_weights[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 1.25555556, 0.678     ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k6wrI5Ab_x4"
      },
      "source": [
        "### Compute Fairness Metrics in Transformed Data\n",
        "\n",
        "Now that we have a transformed dataset, we can check how effective it was in removing bias by calculating the same metrics we used for the original training dataset. As above, we can use the function mean_difference in the BinaryLabelDatasetMetric class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0ubwJbUb_x4"
      },
      "source": [
        "metric_RW_test = BinaryLabelDatasetMetric(\n",
        "    dataset_transf_train, \n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        "  )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFZh_-La6Eq8"
      },
      "source": [
        "Print the difference in mean outcomes and disparate impact in the transformed data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gim6DapUb_x4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b87702-168c-4ef2-9384-b436d94184d1"
      },
      "source": [
        "print(metric_RW_test.mean_difference())\n",
        "print(metric_RW_test.disparate_impact())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.3306690738754696e-16\n",
            "1.0000000000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aG_Glh7Frbc"
      },
      "source": [
        "**Analysis**\n",
        "\n",
        "We now have disparate impact as ~ 1.0, which is desired, as it signifies parity - however, the value for the difference in mean outcomes is positive now (but very close to 0, almost fair), implying SLIGHTLY favorable outcomes for the unprivileged group. This value (3.3306690738754696e-16) is much smaller in magnitude as compared to the value in the original dataset (~ -0.17), where we had favorable outcomes for the privileged group. "
      ]
    }
  ]
}